{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "DATA_DIR = \"/Users/timberzhang/Documents/Documents/2024-JustWatch/Data\"\n",
    "FILL_NAN = np.nan\n",
    "CLUSTER_MIN_EPS = 25\n",
    "CLUSTER_MIN_SAMPLE = 5\n",
    "MIN_DTW_WINDOW = 2\n",
    "\n",
    "VR_SCALE = 0.001207812\n",
    "VR_ZDIST = 1\n",
    "EYE_SAMPLE_RATE = 50\n",
    "EYE_SAMPLE_TIME = (1 / EYE_SAMPLE_RATE) * 1000\n",
    "SCREEN_SIZE = [1280, 720]\n",
    "\n",
    "VIDEO_SIZE = [1920, 1080]\n",
    "VIDEO_FPS = 30\n",
    "BALL_TRAJ = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['24071512_AD.csv',\n",
       " '24070902_AD.csv',\n",
       " '24071009_AD.csv',\n",
       " '24072825_AD.csv',\n",
       " '24070904_AD.csv',\n",
       " '24071617_AD.csv',\n",
       " '24071721_AD.csv',\n",
       " '24071619_AD.csv',\n",
       " '24071615_AD.csv',\n",
       " '24071011_AD.csv',\n",
       " '24070906_AD.csv',\n",
       " 'Test_AD.csv',\n",
       " '24071513_AD.csv',\n",
       " '24072926_AD.csv',\n",
       " '24071008_AD.csv',\n",
       " '24070901_AD.csv',\n",
       " '24072023_AD.csv',\n",
       " '24071616_AD.csv',\n",
       " '24070905_AD.csv',\n",
       " '24070907_AD.csv',\n",
       " '24071010_AD.csv',\n",
       " '24071618_AD.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_list = list(os.walk(DATA_DIR))[0][2]\n",
    "file_list = list(filter(lambda x: \"AD\" in x, file_list))\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['pingpang.csv', 'tennis.csv', '.DS_Store', 'ControlGroupInfo.xlsx',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def fetch_data(dir_path:str, file_list:list, drop_list:list=[]):\n",
    "    \n",
    "    def fetch_eye_data(_raw_eye_data:str):\n",
    "        _eye_data_rows = _raw_eye_data.split(\";\")\n",
    "        eye_data = {}   \n",
    "        names = _eye_data_rows[0].split(\" \")\n",
    "        for idx, row in enumerate(_eye_data_rows):\n",
    "            if idx == 0 : continue\n",
    "\n",
    "            cur_data = row.split(\" \")\n",
    "            try:\n",
    "                eye_data[idx] = {\n",
    "                    names[0] : FILL_NAN if cur_data[0]==\"NaN\" else float(cur_data[0]),\n",
    "                    names[1] : FILL_NAN if cur_data[0]==\"NaN\" else float(cur_data[1]),\n",
    "                    names[2] : FILL_NAN if cur_data[0]==\"NaN\" else float(cur_data[2]),\n",
    "                    names[3] : FILL_NAN if cur_data[0]==\"NaN\" else float(cur_data[3]),\n",
    "                }\n",
    "            except:\n",
    "                eye_data[idx] = {\n",
    "                    names[0] : FILL_NAN,\n",
    "                    names[1] : FILL_NAN,\n",
    "                    names[2] : FILL_NAN,\n",
    "                    names[3] : FILL_NAN,\n",
    "                }\n",
    "\n",
    "        return eye_data\n",
    "\n",
    "\n",
    "    _all_data = {}\n",
    "    for file in file_list:\n",
    "        if file in drop_list: continue\n",
    "        _single_person_data_df = pd.read_csv(os.path.join(dir_path, file))\n",
    "        _single_person_data_dict = {}\n",
    "        _videos = {}\n",
    "\n",
    "        for _, row in _single_person_data_df.iterrows():\n",
    "            _eye_data = fetch_eye_data(row[\"EyeData\"])\n",
    "            v_id = row[\"videoName\"]\n",
    "            if v_id in _single_person_data_dict.keys(): \n",
    "                _videos[v_id] += 1\n",
    "                v_id = v_id + f\"_{_videos[v_id]}\"\n",
    "            else:\n",
    "                _videos[v_id] = 1\n",
    "            _single_person_data_dict[v_id] = _eye_data\n",
    "        \n",
    "        _all_data[file.split(\".\")[0]] = _single_person_data_dict\n",
    "    \n",
    "    return _all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = fetch_data(DATA_DIR, file_list, drop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_trajectory(dir_path:str):\n",
    "    res = {}\n",
    "\n",
    "    p_traj = pd.read_csv(os.path.join(dir_path, \"pingpang.csv\"))\n",
    "    w_traj = pd.read_csv(os.path.join(dir_path, \"tennis.csv\"))\n",
    "    _temp_all = pd.concat([p_traj, w_traj], axis=0)\n",
    "    _temp_all[\"position\"] = _temp_all[\"position\"].apply(lambda x : x.replace(\" \", \"\"))\n",
    "\n",
    "    for v_id, v_df in _temp_all.groupby(by=\"video_name\"):\n",
    "\n",
    "        _x = v_df[\"position\"].apply(lambda x : x.split(\",\")[0][1:]).to_numpy(dtype=np.int16)\n",
    "        _y = v_df[\"position\"].apply(lambda x : x.split(\",\")[1][:-1]).to_numpy(dtype=np.int16)\n",
    "\n",
    "        # reverse the y-axis\n",
    "        _y = (_y - VIDEO_SIZE[1]) * -1\n",
    "\n",
    "        # scale and shift\n",
    "        _x = (_x / VIDEO_SIZE[0]) * SCREEN_SIZE[0] - (SCREEN_SIZE[0] // 2)\n",
    "        _y = (_y / VIDEO_SIZE[1]) * SCREEN_SIZE[1] - (SCREEN_SIZE[1] // 2)\n",
    "\n",
    "        _f = v_df[\"frame_number\"].to_numpy(dtype=np.int16)\n",
    "        _r = v_df[\"round\"].to_numpy(dtype=np.int16)\n",
    "        _temp_df = pd.DataFrame(\n",
    "            np.array([_f, _x, _y, _r])\n",
    "        ).T\n",
    "        _temp_df.index = range(1, _f.size+1)\n",
    "        _temp_df.columns = [\"frame\", \"Ball.x\", \"Ball.y\", \"round\"]\n",
    "\n",
    "        res[v_id] = _temp_df.to_dict()\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BALL_TRAJ = fetch_trajectory(DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.signal import savgol_filter\n",
    "\n",
    "# def smooth_series(series:pd.Series, window_length:int=5, polyorder:int=1):\n",
    "#     # Interpolate the missing values\n",
    "#     series_interpolated = series.interpolate(method='linear')\n",
    "    \n",
    "#     # Apply a Savitzky-Golay filter for smoothing\n",
    "#     smoothed_series = savgol_filter(series_interpolated, window_length=window_length, polyorder=polyorder)\n",
    "    \n",
    "#     return smoothed_series\n",
    "\n",
    "# def smooth_data(data:dict):\n",
    "#     temp = pd.DataFrame(data=data).T\n",
    "#     temp[\"Screen.x\"] = smooth_series(temp[\"Screen.x\"])\n",
    "#     temp[\"Screen.y\"] = smooth_series(temp[\"Screen.y\"])\n",
    "#     return temp.T.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _person in all_data.keys():\n",
    "#     for _video in all_data[_person].keys():\n",
    "#         all_data[_person][_video] = smooth_data(all_data[_person][_video])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saccade Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "def max_circle_radius(df:pd.DataFrame):\n",
    "    centroid_x = df['Screen.x'].mean()\n",
    "    centroid_y = df['Screen.y'].mean()\n",
    "    \n",
    "    distances = np.sqrt((df['Screen.x'] - centroid_x)**2 + (df['Screen.y'] - centroid_y)**2)\n",
    "    \n",
    "    max_radius = distances.max()\n",
    "\n",
    "    if max_radius < VR_SCALE:\n",
    "        return VR_SCALE\n",
    "    else:\n",
    "        return max_radius\n",
    "\n",
    "\n",
    "def compute_stat(name:str, data_list:list):\n",
    "    _res = {}\n",
    "    _res[f\"{name}_Mean\"] = np.mean(data_list)\n",
    "    _res[f\"{name}_Max\"] = np.max(data_list)\n",
    "    _res[f\"{name}_Min\"] = np.min(data_list)\n",
    "    _res[f\"{name}_Std\"] = np.std(data_list)\n",
    "\n",
    "    return _res\n",
    "\n",
    "\n",
    "def compute_saccade_path(df:pd.DataFrame):\n",
    "    _speeds = []\n",
    "    _angles = []\n",
    "\n",
    "    for _c in range(0, df[\"c\"].max()):\n",
    "        _temp_t1 = df[df[\"c\"]==_c]\n",
    "        _temp_t2 = df[df[\"c\"]==_c+1]\n",
    "        \n",
    "        c_x_t1 = _temp_t1[\"Screen.x\"].mean()\n",
    "        c_y_t1 = _temp_t1[\"Screen.y\"].mean()\n",
    "        c_x_t2 = _temp_t2[\"Screen.x\"].mean()\n",
    "        c_y_t2 = _temp_t2[\"Screen.y\"].mean()\n",
    "\n",
    "        _dura = ((_temp_t2[\"t\"].mean() - _temp_t1[\"t\"].mean()) * EYE_SAMPLE_TIME ) / 1000.0\n",
    "        _dist = np.sqrt((c_x_t1 - c_x_t2)**2 + (c_y_t1 - c_y_t2)**2)\n",
    "        _angle = np.arctan(_dist / VR_ZDIST) / np.pi * 180\n",
    "        _angles.append(_angle)\n",
    "\n",
    "        if _dura <= EYE_SAMPLE_TIME / 1000.0:\n",
    "            _speeds.append(0)\n",
    "        else:\n",
    "            _speeds.append( np.divide(_angle, _dura))\n",
    "\n",
    "    return _speeds, _angles\n",
    "\n",
    "\n",
    "def extract_saccade_features(data, video_id):\n",
    "    _fea = {}\n",
    "    temp = np.array([data[\"Screen.x\"], data[\"Screen.y\"], data.index.to_numpy()]).T\n",
    "    temp = pd.DataFrame(temp)\n",
    "    temp.columns=[\"Screen.x\", \"Screen.y\", \"t\"]\n",
    "\n",
    "    db = DBSCAN(eps=CLUSTER_MIN_EPS, min_samples=CLUSTER_MIN_SAMPLE)\n",
    "    cluster_res = db.fit(temp.dropna())\n",
    "    clusters = pd.value_counts(cluster_res.labels_)\n",
    "\n",
    "    if clusters.shape[0] <= 2: \n",
    "        return _fea\n",
    "\n",
    "    # _not_na_index = temp.dropna().index\n",
    "    # temp[\"c\"] = -1\n",
    "    # temp.loc[_not_na_index, \"c\"] = cluster_res.labels_\n",
    "    temp[\"c\"] = cluster_res.labels_\n",
    "    ## map the pixel value to real distance\n",
    "    temp[\"x\"] = temp[\"x\"] * VR_SCALE\n",
    "    temp[\"y\"] = temp[\"y\"] * VR_SCALE\n",
    "\n",
    "    _fea[\"NumOfGazePoints\"] = len(clusters.index) - 1\n",
    "    # \"_g\" for gaze\n",
    "    _g_duration = []\n",
    "    _g_radius = []\n",
    "    _g_density = []\n",
    "    _g_density_t = []\n",
    "    for c, v in clusters.items():\n",
    "        if c == -1: continue\n",
    "        _duration = v * EYE_SAMPLE_TIME\n",
    "        _g_duration.append(_duration)\n",
    "        _circle_r = max_circle_radius(temp[temp[\"c\"]==c]) * 100\n",
    "        _g_radius.append(_circle_r)\n",
    "        _density = v / (np.pi * np.power(_circle_r,2))\n",
    "        _g_density.append(_density)\n",
    "        _g_density_t.append(_density / _duration)\n",
    "\n",
    "    _speeds,_angles = compute_saccade_path(temp)\n",
    "\n",
    "    _fea = {**_fea, **compute_stat(\"GazeRadius\", _g_radius)}\n",
    "    _fea = {**_fea, **compute_stat(\"GazeDuratiuon\", _g_duration)}\n",
    "    _fea = {**_fea, **compute_stat(\"GazeDensity\", _g_density)}\n",
    "    _fea = {**_fea, **compute_stat(\"GazeDensityFrequency\", _g_density_t)}\n",
    "\n",
    "    _fea = {**_fea, **compute_stat(\"SaccadeSpeed\", _speeds)}\n",
    "    _fea = {**_fea, **compute_stat(\"SaccadeAngel\", _angles)}\n",
    "\n",
    "    return _fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_saccade_path_lite(df:pd.DataFrame):\n",
    "    _speeds = [0]\n",
    "    _angles = [0]\n",
    "    indices = list(df.index)\n",
    "    _dura = (1 * EYE_SAMPLE_TIME ) / 1000.0\n",
    "    df[\"Screen.x\"] = df[\"Screen.x\"] * VR_SCALE\n",
    "    df[\"Screen.y\"] = df[\"Screen.y\"] * VR_SCALE\n",
    "\n",
    "    for _i in range(1, len(indices)):\n",
    "        row_1 = df.loc[indices[_i - 1], :]\n",
    "        row_2 = df.loc[indices[_i], :]\n",
    "\n",
    "        _dist = np.sqrt((row_1[\"Screen.x\"] - row_2[\"Screen.x\"])**2 + (row_1[\"Screen.y\"] - row_2[\"Screen.y\"])**2)\n",
    "        _angle = np.arctan(_dist / VR_ZDIST) / np.pi * 180\n",
    "\n",
    "        _angles.append(_angle)\n",
    "        _speeds.append(np.divide(_angle, _dura))\n",
    "\n",
    "    return _speeds, _angles\n",
    "\n",
    "\n",
    "def compute_drop_point_bias_pred(eye_data:pd.DataFrame, eye_index, ball_data:pd.DataFrame, ball_round, eye_drop=\"last\"):\n",
    "    if eye_drop==\"last\":\n",
    "        eye_init = eye_data.iloc[0, :]\n",
    "        eye_final = eye_data.iloc[-1, :]\n",
    "    elif eye_drop==\"fast\":\n",
    "        idx_min = eye_data.index.min()\n",
    "        eye_init = eye_data.loc[eye_index-1 if eye_index-1>idx_min else idx_min, :]\n",
    "        eye_final = eye_data.loc[eye_index, :]\n",
    "    ball_init = ball_data[ball_data[\"round\"]==ball_round].iloc[0, :]\n",
    "    ball_final = ball_data[ball_data[\"round\"]==ball_round].iloc[-1, :]\n",
    "\n",
    "    init_bias = np.sqrt((ball_init[\"Ball.x\"] - eye_init[\"Screen.x\"])**2 + (ball_init[\"Ball.y\"] - eye_init[\"Screen.y\"])**2)\n",
    "    final_bias = np.sqrt((ball_final[\"Ball.x\"] - eye_final[\"Screen.x\"])**2 + (ball_final[\"Ball.y\"] - eye_final[\"Screen.y\"])**2)\n",
    "    return init_bias, final_bias\n",
    "\n",
    "\n",
    "def compute_drop_point_bias_delay(eye_data:pd.DataFrame, eye_index, ball_data:pd.DataFrame, ball_round, eye_drop=\"last\"):\n",
    "    if eye_drop==\"last\":\n",
    "        eye_init = eye_data.iloc[0, :]\n",
    "        eye_final = eye_data.iloc[-1, :]\n",
    "    elif eye_drop==\"fast\":\n",
    "        idx_min = eye_data.index.min()\n",
    "        eye_init = eye_data.loc[eye_index-1 if eye_index-1>idx_min else idx_min, :]\n",
    "        eye_final = eye_data.loc[eye_index, :]\n",
    "    ball_init = ball_data[ball_data[\"round\"]==ball_round-1].iloc[0, :]\n",
    "    ball_final = ball_data[ball_data[\"round\"]==ball_round-1].iloc[-1, :]\n",
    "\n",
    "    init_bias = np.sqrt((ball_init[\"Ball.x\"] - eye_init[\"Screen.x\"])**2 + (ball_init[\"Ball.y\"] - eye_init[\"Screen.y\"])**2)\n",
    "    final_bias = np.sqrt((ball_final[\"Ball.x\"] - eye_final[\"Screen.x\"])**2 + (ball_final[\"Ball.y\"] - eye_final[\"Screen.y\"])**2)\n",
    "    return init_bias, final_bias\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectory Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.metrics import dtw as ts_dtw\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "## eps measured as pixel\n",
    "def compute_traj_overlap(concat_df:pd.DataFrame, eps:float=15.0):\n",
    "    concat_df[\"overlap\"] = concat_df.apply(\n",
    "            lambda row : 1 if np.sqrt((row[\"Screen.x\"] - row[\"Ball.x\"])**2 + (row[\"Screen.y\"] - row[\"Ball.y\"])**2) <= eps else 0,\n",
    "            axis=1\n",
    "        )\n",
    "    return concat_df[\"overlap\"].sum() / concat_df.shape[0]\n",
    "\n",
    "\n",
    "def compute_traj_range_overlap(concat_df:pd.DataFrame, eps:float=15.0, time_range=25):\n",
    "    concat_df[\"overlap\"] = 0\n",
    "    for idx, row in concat_df.iterrows():\n",
    "        _temp_df = concat_df.loc[idx-time_range:idx+time_range, :]\n",
    "        _temp_df[\"overlap\"] = _temp_df.apply(\n",
    "            lambda b_row : 1 if np.sqrt((row[\"Screen.x\"] - b_row[\"Ball.x\"])**2 + (row[\"Screen.y\"] - b_row[\"Ball.y\"])**2) <= eps else 0,\n",
    "            axis=1\n",
    "        )\n",
    "        if _temp_df[\"overlap\"].sum() > 0:\n",
    "            concat_df.loc[idx, \"overlap\"] = 1\n",
    "    return concat_df[\"overlap\"].sum() / concat_df.shape[0]\n",
    "\n",
    "\n",
    "def compute_dtw(line_1:pd.DataFrame, line_2:pd.DataFrame, scale_to_percentage=False, scale_metrics=\"mean\"):\n",
    "    assert line_1.shape[-1] == line_2.shape[-1]\n",
    "\n",
    "    res = ts_dtw(line_1, line_2)\n",
    "\n",
    "    if scale_to_percentage:\n",
    "        mat = cdist(line_1, line_2)\n",
    "        if scale_metrics==\"max\":\n",
    "            res = (res / mat.max()) *100\n",
    "        elif scale_metrics==\"start\":\n",
    "            scale = np.sqrt((line_1.iloc[0, :][\"Screen.x\"] - line_2.iloc[0, :][\"Ball.x\"])**2 + (line_1.iloc[0, :][\"Screen.y\"] - line_2.iloc[0, :][\"Ball.y\"])**2)\n",
    "            res = (res / scale) * 100\n",
    "        elif scale_metrics==\"end\":\n",
    "            scale = np.sqrt((line_1.iloc[-1, :][\"Screen.x\"] - line_2.iloc[-1, :][\"Ball.x\"])**2 + (line_1.iloc[-1, :][\"Screen.y\"] - line_2.iloc[-1, :][\"Ball.y\"])**2)\n",
    "            res = (res / scale) * 100\n",
    "        else:\n",
    "            res = (res / mat.mean()) *100 \n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def compute_gradient_dtw(line_1:pd.DataFrame, line_2:pd.DataFrame, order:int=1, time_scale=1, scale_to_percentage=False):\n",
    "    assert line_1.shape == line_2.shape\n",
    "    assert \"time\" in line_1.columns or \"frame\" in line_1.columns, \"Please include index, time, or frame (named 'time') in the line_1 DataFrame\"\n",
    "    assert \"time\" in line_2.columns or \"frame\" in line_2.columns, \"Please include index, time, or frame (named 'time') in the line_2 DataFrame\"\n",
    "    assert order>=1, \"Gradient order must larger or equal to 1\"\n",
    "    \n",
    "    ## convert frame to time\n",
    "    if \"frame\" in line_1.columns:\n",
    "        line_1[\"time\"] = line_1[\"frame\"] * EYE_SAMPLE_TIME * time_scale\n",
    "    if \"frame\" in line_2.columns:\n",
    "        line_2[\"time\"] = line_2[\"frame\"] * EYE_SAMPLE_TIME * time_scale\n",
    "\n",
    "    ## create gradient column\n",
    "    line_1_grad_col, line_2_grad_col = [], []\n",
    "    for col in line_1.columns:\n",
    "        if col == \"time\": continue\n",
    "        line_1[f\"{col}.grad\"] = line_1[col]\n",
    "        line_1_grad_col.append(f\"{col}.grad\")\n",
    "    for col in line_2.columns:\n",
    "        if col == \"time\": continue\n",
    "        line_2[f\"{col}.grad\"] = line_2[col]\n",
    "        line_2_grad_col.append(f\"{col}.grad\")\n",
    "    \n",
    "    ## compute the gradient\n",
    "    for _ in range(0, order):\n",
    "        for col in line_1_grad_col:\n",
    "            line_1[col] = np.gradient(line_1[col], line_1[\"time\"])\n",
    "        for col in line_2_grad_col:\n",
    "            line_2[col] = np.gradient(line_2[col], line_2[\"time\"])\n",
    "\n",
    "    return compute_dtw(line_1[line_1_grad_col], line_2[line_2_grad_col], scale_to_percentage=scale_to_percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interplate_and_align(base_df:pd.DataFrame, align_df:pd.DataFrame, base_rate:int, align_rate:int, convert_dist=False):\n",
    "    share_rate = abs(base_rate * align_rate) // np.gcd(base_rate, align_rate)\n",
    "    \n",
    "    align_df[\"frame\"] = align_df[\"frame\"] * (share_rate // align_rate)\n",
    "    temp_index= np.array(range(1, int(base_df[\"frame\"].max()+1) * (share_rate // base_rate)))\n",
    "\n",
    "    temp_time_df = pd.DataFrame(temp_index, index=temp_index, columns=[\"frame\"])\n",
    "    _index = temp_time_df.index\n",
    "    temp_time_df = temp_time_df.merge(align_df, how=\"left\", on=\"frame\")\n",
    "    temp_time_df.index = _index\n",
    "    ## interplate\n",
    "    for col in temp_time_df.columns:\n",
    "        if col==\"round\": continue\n",
    "        temp_time_df[col] = temp_time_df[col].interpolate(method='linear')\n",
    "    ## ensure first row is not empty\n",
    "    temp_time_df.ffill(inplace=True)\n",
    "    temp_time_df.bfill(inplace=True)\n",
    "    \n",
    "    base_df[\"frame\"] = base_df[\"frame\"] * (share_rate // base_rate)\n",
    "    _index = base_df.index\n",
    "    alined_df = base_df.merge(temp_time_df, how=\"left\", on=\"frame\", )\n",
    "    alined_df.index = _index\n",
    "    alined_df[\"frame\"] = alined_df[\"frame\"] // (share_rate // base_rate)\n",
    "\n",
    "    if convert_dist:\n",
    "        alined_df = alined_df * VR_SCALE\n",
    "        alined_df[\"frame\"] = alined_df[\"frame\"] // VR_SCALE\n",
    "\n",
    "    alined_df.ffill(inplace=True)\n",
    "    alined_df.bfill(inplace=True)\n",
    "\n",
    "    return alined_df\n",
    "\n",
    "\n",
    "def extract_trajectory(eye_data_df:pd.DataFrame, video_id, scale_to_percentage=False):\n",
    "    res = {}\n",
    "    if not BALL_TRAJ: \n",
    "        return res\n",
    "\n",
    "    eye_data_df[\"frame\"] = eye_data_df.index\n",
    "    ball_data_df = pd.DataFrame(BALL_TRAJ[video_id])\n",
    "    \n",
    "    aligned_df = interplate_and_align(eye_data_df, ball_data_df, EYE_SAMPLE_RATE, VIDEO_FPS, convert_dist=False)\n",
    "    # aligned_df.rename(columns={'x':'Ball.x', \"y\":\"Ball.y\"}, inplace=True)\n",
    "    \n",
    "    _traj_overlap = compute_traj_overlap(aligned_df)\n",
    "    _traj_range_overlap = compute_traj_range_overlap(aligned_df)\n",
    "    _all_dtw = compute_dtw(\n",
    "            line_1=aligned_df.loc[:, [\"Screen.x\", \"Screen.y\"]],\n",
    "            line_2=aligned_df.loc[:, [\"Ball.x\", \"Ball.y\"]],\n",
    "            scale_to_percentage=scale_to_percentage\n",
    "        )\n",
    "    _all_speed_dtw = compute_gradient_dtw(\n",
    "            line_1=aligned_df.loc[:, [\"frame\", \"Screen.x\", \"Screen.y\"]],\n",
    "            line_2=aligned_df.loc[:, [\"frame\", \"Ball.x\", \"Ball.y\"]],\n",
    "            order=1,\n",
    "            scale_to_percentage=scale_to_percentage\n",
    "    )\n",
    "    _all_accelerate_dtw = compute_gradient_dtw(\n",
    "            line_1=aligned_df.loc[:, [\"frame\", \"Screen.x\", \"Screen.y\"]],\n",
    "            line_2=aligned_df.loc[:, [\"frame\", \"Ball.x\", \"Ball.y\"]],\n",
    "            order=2,\n",
    "            scale_to_percentage=scale_to_percentage\n",
    "    )\n",
    "\n",
    "    res[\"AllTrajectoryOverlap\"] = _traj_overlap * 100\n",
    "    res[\"AllTrajectoryRangeOverlap\"] = _traj_range_overlap * 100\n",
    "    if scale_to_percentage:\n",
    "        res[\"AllTrajectoryDTW\"] = _all_dtw\n",
    "        res[\"AllTrajectoryDTWPerSec\"] = _all_dtw / (eye_data_df.shape[0] * EYE_SAMPLE_TIME / 1000)\n",
    "        res[\"AllTrajectorySpeedDTW\"] = _all_speed_dtw\n",
    "        res[\"AllTrajectorySpeedDTWPerSec\"] = _all_speed_dtw / (eye_data_df.shape[0] * EYE_SAMPLE_TIME / 1000)\n",
    "        res[\"AllTrajectoryAccelerateDTW\"] = _all_accelerate_dtw\n",
    "        res[\"AllTrajectoryAcceleratePerSec\"] = _all_accelerate_dtw / (eye_data_df.shape[0] * EYE_SAMPLE_TIME / 1000)\n",
    "    else:\n",
    "        res[\"AllTrajectoryDTW\"] = _all_dtw * VR_SCALE\n",
    "        res[\"AllTrajectoryDTWPerSec\"] = _all_dtw * VR_SCALE / (eye_data_df.shape[0] * EYE_SAMPLE_TIME / 1000)\n",
    "        res[\"AllTrajectorySpeedDTW\"] = _all_speed_dtw * VR_SCALE\n",
    "        res[\"AllTrajectorySpeedDTWPerSec\"] = _all_speed_dtw * VR_SCALE / (eye_data_df.shape[0] * EYE_SAMPLE_TIME / 1000)\n",
    "        res[\"AllTrajectoryAccelerateDTW\"] = _all_accelerate_dtw * VR_SCALE\n",
    "        res[\"AllTrajectoryAccelerateDTWPerSec\"] = _all_accelerate_dtw * VR_SCALE / (eye_data_df.shape[0] * EYE_SAMPLE_TIME / 1000)\n",
    "    \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_saccade_features_lite(round_index, data:pd.DataFrame, ball_data_df):\n",
    "    _fea = {}\n",
    "\n",
    "    _speeds, _angles = compute_saccade_path_lite(data)\n",
    "    _fea = {**_fea, **compute_stat(\"SaccadeSpeed\", _speeds)}\n",
    "    _fea = {**_fea, **compute_stat(\"SaccadeAngel\", _angles)}\n",
    "\n",
    "    round_start_index = ball_data_df[ball_data_df[\"round\"]==round_index].index[0]\n",
    "    eye_start_index = data.index[0]\n",
    "    _fea[\"SaccadeDelay\"] = (eye_start_index-round_index) * EYE_SAMPLE_TIME\n",
    "\n",
    "    # _fea[\"SaccadeTimeShift\"] = (np.argmax(_speeds) - (data.shape[0] // 2)) * EYE_SAMPLE_TIME\n",
    "\n",
    "    # bias_res = compute_drop_point_bias_pred(\n",
    "    #     eye_data=data,\n",
    "    #     eye_index=data.index[np.argmax(_speeds)],\n",
    "    #     ball_data=ball_data_df,\n",
    "    #     ball_round=round_index\n",
    "    # )\n",
    "    # _fea[\"SaccadeDropBiasPred_Init\"] = bias_res[0] * VR_SCALE\n",
    "    # _fea[\"SaccadeDropBiasPred_Final\"] = bias_res[1] * VR_SCALE\n",
    "\n",
    "    # bias_res = compute_drop_point_bias_delay(\n",
    "    #     eye_data=data,\n",
    "    #     eye_index=data.index[np.argmax(_speeds)],\n",
    "    #     ball_data=ball_data_df,\n",
    "    #     ball_round=round_index\n",
    "    # )\n",
    "    # _fea[\"SaccadeDropBiasDelay_Init\"] = bias_res[0] * VR_SCALE\n",
    "    # _fea[\"SaccadeDropBiasDelay_Final\"] = bias_res[1] * VR_SCALE\n",
    "\n",
    "    return _fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_trajectory_lite(round_index, data:pd.DataFrame, ball_data_df):\n",
    "    _fea = {}\n",
    "    \n",
    "    _ball_df = ball_data_df[ball_data_df[\"round\"]==round_index]\n",
    "    _dtw = compute_dtw(\n",
    "            line_1=data.loc[:, [\"Screen.x\", \"Screen.y\"]],\n",
    "            line_2=_ball_df.loc[:, [\"Ball.x\", \"Ball.y\"]],\n",
    "            # scale_to_percentage=True,\n",
    "            # scale_metrics=\"start\"\n",
    "        )\n",
    "    \n",
    "    _fea[\"TrajectoryDTW\"] = _dtw\n",
    "\n",
    "    return _fea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Pattern Match Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import KDTree\n",
    "\n",
    "\n",
    "def count_points_in_radius(ball_df:pd.DataFrame, eye_df:pd.DataFrame, radius):\n",
    "    # Build a k-d tree from the points DataFrame\n",
    "    points_tree = KDTree(eye_df[['Screen.x', 'Screen.y']])\n",
    "    \n",
    "    count_list = []\n",
    "    \n",
    "    for i, trajectory_point in ball_df.iterrows():\n",
    "        # Query the k-d tree for points within the radius\n",
    "        indices = points_tree.query_ball_point([trajectory_point['Ball.x'], trajectory_point['Ball.y']], r=radius)\n",
    "        count_list += indices\n",
    "    \n",
    "    return list(set(count_list))\n",
    "\n",
    "def find_match_round(eye_data_df:pd.DataFrame, video_id, radius=15, inner_percent=0.9):\n",
    "    res = []\n",
    "    if not BALL_TRAJ: \n",
    "        return res\n",
    "\n",
    "    eye_data_df[\"frame\"] = eye_data_df.index\n",
    "    ball_data_df = pd.DataFrame(BALL_TRAJ[video_id])\n",
    "    assert \"round\" in ball_data_df.columns, \"Missing 'round' in ball trajectory file\"\n",
    "\n",
    "    aligned_df = interplate_and_align(eye_data_df, ball_data_df, EYE_SAMPLE_RATE, VIDEO_FPS, convert_dist=False)\n",
    "\n",
    "    for _round in aligned_df[\"round\"].value_counts().index:\n",
    "        temp = aligned_df[aligned_df[\"round\"]==_round]\n",
    "        inner_counts = count_points_in_radius(temp.loc[:, [\"Ball.x\", \"Ball.y\"]], temp.loc[:, [\"Screen.x\", \"Screen.y\"]], radius=radius)\n",
    "\n",
    "        # check_df = temp.iloc[inner_counts, :]\n",
    "        # max_x, min_x = check_df[\"Screen.x\"].max(), check_df[\"Screen.x\"].min()\n",
    "        # max_y, min_y = check_df[\"Screen.y\"].max(), check_df[\"Screen.y\"].min()\n",
    "        # dis = np.sqrt((max_x - min_x)**2 + (max_y - min_y)**2)\n",
    "        dis = radius\n",
    "\n",
    "        if len(inner_counts) / temp.shape[0] > inner_percent and dis >= radius:\n",
    "            res.append(_round)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def find_match_round_hit(eye_data_df:pd.DataFrame, video_id, time_range=10, dist=250):\n",
    "    res ={}\n",
    "    if not BALL_TRAJ: \n",
    "        return res\n",
    "\n",
    "    eye_data_df[\"frame\"] = eye_data_df.index\n",
    "    ball_data_df = pd.DataFrame(BALL_TRAJ[video_id])\n",
    "    assert \"round\" in ball_data_df.columns, \"Missing 'round' in ball trajectory file\"\n",
    "\n",
    "    aligned_df = interplate_and_align(eye_data_df, ball_data_df, EYE_SAMPLE_RATE, VIDEO_FPS, convert_dist=False)\n",
    "\n",
    "    aligned_df[\"hit\"] = aligned_df[\"round\"] - aligned_df[\"round\"].shift(1, fill_value=1)\n",
    "    hits_indices = aligned_df[aligned_df[\"hit\"]==1].index\n",
    "\n",
    "    for idx, _hit in enumerate(hits_indices):\n",
    "        index_range = [_hit-time_range, _hit+time_range]\n",
    "        temp = aligned_df.loc[index_range[0]:index_range[1], :]\n",
    "        eye_max_dist = np.sqrt((temp[\"Screen.x\"].max() - temp[\"Screen.x\"].min())**2 + (temp[\"Screen.y\"].max() - temp[\"Screen.y\"].min())**2)\n",
    "\n",
    "        if eye_max_dist >= dist:\n",
    "            res[aligned_df.loc[_hit, \"round\"]] = list(temp.index)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "\n",
    "def given_minmax_scale(data:pd.DataFrame, minmax, feature_range=[0,1], axis=0):\n",
    "    res = []\n",
    "    for _i in data.index if axis==1 else data.columns:\n",
    "        scale = (feature_range[1] - feature_range[0]) / (minmax[1] - minmax[0])\n",
    "        X_scaled = scale * (data[_i] - minmax[0])\n",
    "        res.append(X_scaled)\n",
    "\n",
    "    return pd.DataFrame(res) if axis==1 else pd.DataFrame(res).T\n",
    "\n",
    "\n",
    "def interplate_enlarge(ori_df:pd.DataFrame, size:int):\n",
    "    ori_df = ori_df.reset_index(drop=True)\n",
    "    ori_df.index = [int(np.round(i * (size / ori_df.shape[0]))) for i in ori_df.index ]\n",
    "    new_index = pd.Index(range(0, min(size, ori_df.index[-1]+1)))\n",
    "    # print(new_index)\n",
    "    # print(size / ori_df.shape[0])\n",
    "    ori_df = ori_df.reindex(new_index).interpolate()\n",
    "    return ori_df\n",
    "\n",
    "\n",
    "def find_match_round_dtw(eye_data_df:pd.DataFrame, video_id, order=0, scale_raw_data=False):\n",
    "    res = {}\n",
    "    dtw_res = {}\n",
    "    if not BALL_TRAJ: \n",
    "        return res\n",
    "\n",
    "    eye_data_df[\"frame\"] = eye_data_df.index\n",
    "    ball_data_df = pd.DataFrame(BALL_TRAJ[video_id])\n",
    "    assert \"round\" in ball_data_df.columns, \"Missing 'round' in ball trajectory file\"\n",
    "\n",
    "    aligned_df = interplate_and_align(eye_data_df, ball_data_df, EYE_SAMPLE_RATE, VIDEO_FPS, convert_dist=False)\n",
    "    if scale_raw_data:\n",
    "        aligned_df.loc[:, [\"Screen.x\", \"Ball.x\", \"Screen.y\", \"Ball.y\"]] = minmax_scale(aligned_df.loc[:, [\"Screen.x\", \"Ball.x\", \"Screen.y\", \"Ball.y\"]], axis=0)\n",
    "\n",
    "    for _round in aligned_df[\"round\"].value_counts(sort=False).index:\n",
    "        temp = aligned_df[aligned_df[\"round\"]==_round]\n",
    "\n",
    "        match_indice = None\n",
    "        min_dtw = np.inf\n",
    "        for idx in temp.index:\n",
    "            for window_size in range(MIN_DTW_WINDOW, temp.shape[0]):\n",
    "                # temp_window = aligned_df.loc[_shift_idx:_shift_idx+window_size, :]\n",
    "                temp_window = aligned_df.loc[ idx : idx + window_size, :]\n",
    "                if temp_window.shape[0] < MIN_DTW_WINDOW: continue\n",
    "                _indices = temp_window.index\n",
    "\n",
    "                if temp_window.shape[0] < temp.shape[0]:\n",
    "                    temp_window = interplate_enlarge(temp_window, size=temp.shape[0])\n",
    "\n",
    "                if order==0:\n",
    "                    _dtw = compute_dtw(\n",
    "                        line_1 = temp.loc[:, [\"Ball.x\", \"Ball.y\"]],\n",
    "                        line_2 = temp_window.loc[:, [\"Screen.x\", \"Screen.y\"]],\n",
    "                        scale_to_percentage=False\n",
    "                    )\n",
    "                elif order>0:\n",
    "                    _dtw = compute_gradient_dtw(\n",
    "                            line_1=temp.loc[:, [\"frame\", \"Ball.x\", \"Ball.y\"]],\n",
    "                            line_2=temp_window.loc[:, [\"frame\", \"Screen.x\", \"Screen.y\"]],\n",
    "                            order=order,\n",
    "                            scale_to_percentage=False\n",
    "                    )\n",
    "                else:\n",
    "                    raise Exception(\"Order of gradient must be positive\")\n",
    "                \n",
    "                if _dtw < min_dtw:\n",
    "                    min_dtw = _dtw\n",
    "                    match_indice = _indices\n",
    "              \n",
    "        dtw_res[_round] = min_dtw\n",
    "        res[_round] = match_indice\n",
    "\n",
    "    return res, dtw_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_match_round_dtw_kmp(eye_data_df:pd.DataFrame, video_id, order=0, scale_raw_data=False):\n",
    "    res = {}\n",
    "    dtw_res = {}\n",
    "    # dtw_value = []\n",
    "    if not BALL_TRAJ: \n",
    "        return res\n",
    "\n",
    "    eye_data_df[\"frame\"] = eye_data_df.index\n",
    "    ball_data_df = pd.DataFrame(BALL_TRAJ[video_id])\n",
    "    assert \"round\" in ball_data_df.columns, \"Missing 'round' in ball trajectory file\"\n",
    "\n",
    "    aligned_df = interplate_and_align(eye_data_df, ball_data_df, EYE_SAMPLE_RATE, VIDEO_FPS, convert_dist=False)\n",
    "    if scale_raw_data:\n",
    "        aligned_df.loc[:, [\"Screen.x\", \"Ball.x\", \"Screen.y\", \"Ball.y\"]] = minmax_scale(aligned_df.loc[:, [\"Screen.x\", \"Ball.x\", \"Screen.y\", \"Ball.y\"]], axis=0)\n",
    "\n",
    "    for _round in aligned_df[\"round\"].value_counts(sort=False).index:\n",
    "        temp = aligned_df[aligned_df[\"round\"]==_round]\n",
    "\n",
    "        match_indice = None\n",
    "        min_dtw = np.inf\n",
    "        _shift_idx = temp.index[0]\n",
    "        _last_idx = temp.index[0] + MIN_DTW_WINDOW\n",
    "        # for window_size in range(MIN_DTW_WINDOW, temp.shape[0]):\n",
    "        max_idx = list(aligned_df[(aligned_df[\"round\"]==_round+1) | (aligned_df[\"round\"]==_round)].index)[-1]\n",
    "\n",
    "        while _last_idx < max_idx:\n",
    "            # temp_window = aligned_df.loc[_shift_idx:_shift_idx+window_size, :]\n",
    "            temp_window = aligned_df.loc[ _shift_idx : _last_idx, :]\n",
    "            _indices = temp_window.index\n",
    "\n",
    "            if temp_window.shape[0] < temp.shape[0]:\n",
    "                temp_window = interplate_enlarge(temp_window, size=temp.shape[0])\n",
    "\n",
    "            if temp_window.shape[0] < MIN_DTW_WINDOW: continue\n",
    "\n",
    "            if order==0:\n",
    "                _dtw = compute_dtw(\n",
    "                    line_1 = temp.loc[:, [\"Ball.x\", \"Ball.y\"]],\n",
    "                    line_2 = temp_window.loc[:, [\"Screen.x\", \"Screen.y\"]],\n",
    "                    scale_to_percentage=False\n",
    "                )\n",
    "            elif order>0:\n",
    "                _dtw = compute_gradient_dtw(\n",
    "                        line_1=temp.loc[:, [\"frame\", \"Ball.x\", \"Ball.y\"]],\n",
    "                        line_2=temp_window.loc[:, [\"frame\", \"Screen.x\", \"Screen.y\"]],\n",
    "                        order=order,\n",
    "                        scale_to_percentage=False\n",
    "                )\n",
    "            else:\n",
    "                raise Exception(\"Order of gradient must be positive\")\n",
    "            \n",
    "            _last_idx += 1\n",
    "            if _dtw < min_dtw:\n",
    "                min_dtw = _dtw\n",
    "                match_indice = _indices\n",
    "            else:\n",
    "                _shift_idx = _last_idx\n",
    "                _last_idx = _last_idx + MIN_DTW_WINDOW\n",
    "\n",
    "        dtw_res[_round] = min_dtw\n",
    "        res[_round] = match_indice\n",
    "\n",
    "    return res, dtw_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Proper Hyper-Parameter for Test Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_match_hit(data, video_id):\n",
    "    data_df = pd.DataFrame(data).T\n",
    "    data_df.ffill(inplace=True)\n",
    "    data_df.bfill(inplace=True)\n",
    "    \n",
    "    if \"_\" in video_id:\n",
    "        video_id = video_id.split(\"_\")[0]\n",
    "\n",
    "    res = {}\n",
    "    for r in [5, 7, 10, 15]:\n",
    "        for d in [100,200,300,350,400]:\n",
    "            count_res = find_match_round_hit(data_df.loc[:, [\"Screen.x\", \"Screen.y\"]], video_id, time_range=r, dist=d)\n",
    "            res[f\"Time Range {r}-Dist {d}\"] = len(count_res)\n",
    "            # res[f\"Radius {r} match round\"] = count_res\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_match_round(data, video_id):\n",
    "    data_df = pd.DataFrame(data).T\n",
    "    data_df.ffill(inplace=True)\n",
    "    data_df.bfill(inplace=True)\n",
    "    \n",
    "    if \"_\" in video_id:\n",
    "        video_id = video_id.split(\"_\")[0]\n",
    "\n",
    "    res = {}\n",
    "    for r in [25, 50, 75, 100]:\n",
    "        count_res = find_match_round(data_df.loc[:, [\"Screen.x\", \"Screen.y\"]], video_id, radius=r)\n",
    "        res[f\"Cover Radius {r}\"] = len(count_res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_match(method=\"\"):\n",
    "    all_people_match = {}\n",
    "    for _person in all_data.keys():\n",
    "        _person_fea = {}\n",
    "\n",
    "        for _video in all_data[_person].keys():\n",
    "            if method==\"hit\":\n",
    "                _person_fea[_video] = test_match_hit(all_data[_person][_video], _video)\n",
    "            elif method==\"round\":\n",
    "                _person_fea[_video] = test_match_round(all_data[_person][_video], _video)\n",
    "            else:\n",
    "                raise Exception(\"methods not support\")\n",
    "\n",
    "        all_people_match[_person] = _person_fea\n",
    "    \n",
    "    return all_people_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# if os.path.exists(\"match_round_res.json\"):\n",
    "#     with open(\"match_round_res.json\", \"r\") as f:\n",
    "#         match_round_res = json.load(f)\n",
    "# else:\n",
    "#     match_round_res = test_match(\"hit\")\n",
    "#     with open(\"match_round_res.json\", \"w\") as f:\n",
    "#         json.dump(match_round_res, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_hit(match_round_res, measure=\"mean\"):\n",
    "    stat = None\n",
    "    for idx, _f in enumerate(file_list):\n",
    "        _p = _f.split(\".\")[0]\n",
    "        if measure==\"median\":\n",
    "            _p_stat = pd.DataFrame(match_round_res[_p]).T.median()\n",
    "        elif measure==\"min\":\n",
    "            _p_stat = pd.DataFrame(match_round_res[_p]).T.min()\n",
    "        elif measure==\"max\":\n",
    "            _p_stat = pd.DataFrame(match_round_res[_p]).T.max()\n",
    "        else:\n",
    "            _p_stat = pd.DataFrame(match_round_res[_p]).T.mean()\n",
    "\n",
    "        if idx==0:\n",
    "            stat = _p_stat\n",
    "        else:\n",
    "            stat.join(_p_stat)\n",
    "\n",
    "        return stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel to Angle: 100-> 6.886893402895522\n",
      "Pixel to Angle: 200-> 13.58034668174109\n",
      "Pixel to Angle: 300-> 19.91765997635866\n",
      "Pixel to Angle: 350-> 22.915443016760896\n",
      "Pixel to Angle: 400-> 25.786340252252728\n"
     ]
    }
   ],
   "source": [
    "print(\"Pixel to Angle: 100->\", np.arctan(100 * VR_SCALE / VR_ZDIST) / np.pi * 180)\n",
    "print(\"Pixel to Angle: 200->\", np.arctan(200 * VR_SCALE / VR_ZDIST) / np.pi * 180)\n",
    "print(\"Pixel to Angle: 300->\", np.arctan(300 * VR_SCALE / VR_ZDIST) / np.pi * 180)\n",
    "print(\"Pixel to Angle: 350->\", np.arctan(350 * VR_SCALE / VR_ZDIST) / np.pi * 180)\n",
    "print(\"Pixel to Angle: 400->\", np.arctan(400 * VR_SCALE / VR_ZDIST) / np.pi * 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel to Angle: 360-> 23.499997351668693\n",
      "Pixel to Angle: -360-> -23.499997351668693\n",
      "Pixel to Angle: 640-> 37.704011712943334\n",
      "Pixel to Angle: -640-> -37.704011712943334\n",
      "Pixel to Angle: 734-> 41.558079394134964\n",
      "Pixel to Angle: -734-> -41.558079394134964\n"
     ]
    }
   ],
   "source": [
    "print(\"Pixel to Angle: 360->\", np.arctan(360 * VR_SCALE / VR_ZDIST) / np.pi * 180)\n",
    "print(\"Pixel to Angle: -360->\", np.arctan(-360 * VR_SCALE / VR_ZDIST) / np.pi * 180)\n",
    "print(\"Pixel to Angle: 640->\", np.arctan(640 * VR_SCALE / VR_ZDIST) / np.pi * 180)\n",
    "print(\"Pixel to Angle: -640->\", np.arctan(-640 * VR_SCALE / VR_ZDIST) / np.pi * 180)\n",
    "print(\"Pixel to Angle: 734->\", np.arctan(734 * VR_SCALE / VR_ZDIST) / np.pi * 180)\n",
    "print(\"Pixel to Angle: -734->\", np.arctan(-734 * VR_SCALE / VR_ZDIST) / np.pi * 180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main extrat features function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_round(rounds:dict, data_df:pd.DataFrame, video_id:str):\n",
    "    res = {}\n",
    "    ball_data_df = pd.DataFrame(BALL_TRAJ[video_id])\n",
    "    for round_index, round_indices in rounds.items():\n",
    "        round_res = extract_saccade_features_lite(round_index, data_df.loc[round_indices, [\"Screen.x\", \"Screen.y\"]], ball_data_df)\n",
    "        # res[round_index] = round_res\n",
    "        traj_res = extract_trajectory_lite(round_index, data_df.loc[round_indices, [\"Screen.x\", \"Screen.y\"]], ball_data_df)\n",
    "        res[round_index] = {**round_res, **traj_res}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"yes.txt\", \"r\") as f:\n",
    "    temp = f.readlines()\n",
    "LABEL_ROUNDS = {}\n",
    "for _str in temp:\n",
    "    _str = _str.replace(\"\\n\", \"\")\n",
    "    _video_id = _str.split(\":\")[0]\n",
    "    if len(_str.split(\":\")[1])==0: continue\n",
    "    _rounds = [float(j) for j in _str.split(\":\")[1].split(\";\")]\n",
    "    LABEL_ROUNDS[_video_id] = _rounds\n",
    "\n",
    "\n",
    "def label_round_hit(eye_data_df:pd.DataFrame, video_id,):\n",
    "    res ={}\n",
    "    if not BALL_TRAJ: \n",
    "        return res\n",
    "\n",
    "    eye_data_df[\"frame\"] = eye_data_df.index\n",
    "    ball_data_df = pd.DataFrame(BALL_TRAJ[video_id.split(\"_\")[0]])\n",
    "    assert \"round\" in ball_data_df.columns, \"Missing 'round' in ball trajectory file\"\n",
    "\n",
    "    aligned_df = interplate_and_align(eye_data_df, ball_data_df, EYE_SAMPLE_RATE, VIDEO_FPS, convert_dist=False)\n",
    "    try:\n",
    "        _rounds = LABEL_ROUNDS[video_id]\n",
    "    except:\n",
    "        return {}\n",
    "    \n",
    "    for _r in _rounds:\n",
    "        if video_id.startswith(\"p\"):\n",
    "            res[_r] = aligned_df[aligned_df[\"round\"]==_r+1].index.to_list()\n",
    "            if len(res[_r])==0:\n",
    "                res[_r] = aligned_df[aligned_df[\"round\"]==_r].index.to_list()\n",
    "        else:\n",
    "            res[_r] = aligned_df[aligned_df[\"round\"]==_r].index.to_list()\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_find_match_round_dtw(eye_data:pd.DataFrame, video_id, order, scale_raw_data, mode=\"fast\", dtw_th=1, dist_th=10):\n",
    "    if mode==\"fast\":\n",
    "        rounds, dtw_res = find_match_round_dtw_kmp(eye_data_df=eye_data, video_id=video_id, order=order, scale_raw_data=scale_raw_data)\n",
    "    elif mode==\"greedy\":\n",
    "        rounds, dtw_res = find_match_round_dtw(eye_data_df=eye_data, video_id=video_id, order=order, scale_raw_data=scale_raw_data)\n",
    "\n",
    "    res = {}\n",
    "    for _round, _round_index in rounds.items():\n",
    "        if (max_circle_radius(eye_data.loc[_round_index, :]) >= dist_th) and (dtw_res[_round] <= dtw_th):\n",
    "            res[_round] = _round_index\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data, video_id):\n",
    "    data_df = pd.DataFrame(data).T\n",
    "    data_df.ffill(inplace=True)\n",
    "    data_df.bfill(inplace=True)\n",
    "    \n",
    "    # match_rounds = label_round_hit(data_df.loc[:, [\"Screen.x\", \"Screen.y\"]], video_id)\n",
    "\n",
    "\n",
    "    if \"_\" in video_id:\n",
    "        test_video = video_id.split(\"_\")[0]\n",
    "    else:\n",
    "        test_video = video_id\n",
    "\n",
    "    match_rounds = threshold_find_match_round_dtw(data_df, test_video, order=0, scale_raw_data=True, mode=\"fast\")\n",
    "    # match_rounds = find_match_round_hit(data_df.loc[:, [\"Screen.x\", \"Screen.y\"]], video_id, time_range=7, dist=300)\n",
    "    saccade_features = extract_features_round(match_rounds, data_df.loc[:, [\"Screen.x\", \"Screen.y\"]], test_video)\n",
    "    \n",
    "    return saccade_features\n",
    "\n",
    "    # saccade_features = extract_saccade_features(match_rounds, data_df.loc[:, [\"Screen.x\", \"Screen.y\"]], video_id)\n",
    "    # trajectory_features = extract_trajectory(data_df.loc[:, [\"Screen.x\", \"Screen.y\"]], video_id, scale_to_percentage=True)\n",
    "\n",
    "    # return {**saccade_features, **trajectory_features}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features of all Participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_people_fea = {}\n",
    "video_list= []\n",
    "for _person in all_data.keys():\n",
    "    if not _person == \"24071512_AD\": continue\n",
    "    _person_fea = {}\n",
    "\n",
    "    for _video in all_data[_person].keys():\n",
    "        # if not _video == \"p7\": continue\n",
    "        if not _video in video_list: video_list.append(_video)\n",
    "        \n",
    "        fea_res = extract_features(data=all_data[_person][_video], video_id=_video)\n",
    "        if fea_res:\n",
    "            _person_fea[_video] = fea_res\n",
    "\n",
    "    all_people_fea[_person] = _person_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_video_res(all_people_fea, video_id):\n",
    "    res = {}\n",
    "    for _p, person_fea in all_people_fea.items():\n",
    "        try:\n",
    "            for _r, _fea in person_fea[video_id].items():\n",
    "                res[f\"{_p}-{_r}\"] = _fea\n",
    "        except:\n",
    "            continue\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_person_res(all_people_fea, people_id):\n",
    "    res = {}\n",
    "    for _v, video_fea in all_people_fea[people_id].items():\n",
    "        try:\n",
    "            for _r, _fea in video_fea.items():\n",
    "                res[f\"{_v}-{_r}\"] = _fea\n",
    "        except:\n",
    "            continue\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_fea = single_person_res(all_people_fea=all_people_fea, people_id=\"24071512_AD\")\n",
    "pd.DataFrame(person_fea).T.to_csv(\"24071512_AD_dtw_fast_rounds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SaccadeSpeed_Mean</th>\n",
       "      <th>SaccadeSpeed_Max</th>\n",
       "      <th>SaccadeSpeed_Min</th>\n",
       "      <th>SaccadeSpeed_Std</th>\n",
       "      <th>SaccadeAngel_Mean</th>\n",
       "      <th>SaccadeAngel_Max</th>\n",
       "      <th>SaccadeAngel_Min</th>\n",
       "      <th>SaccadeAngel_Std</th>\n",
       "      <th>SaccadeDelay</th>\n",
       "      <th>TrajectoryDTW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24071512_AD-3.0</th>\n",
       "      <td>82.640553</td>\n",
       "      <td>413.202767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.281107</td>\n",
       "      <td>1.652811</td>\n",
       "      <td>8.264055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.305622</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>300.162880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24071512_AD-8.0</th>\n",
       "      <td>304.883800</td>\n",
       "      <td>654.553153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>269.090155</td>\n",
       "      <td>6.097676</td>\n",
       "      <td>13.091063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.381803</td>\n",
       "      <td>3620.0</td>\n",
       "      <td>268.727935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24071512_AD-10.0</th>\n",
       "      <td>162.601117</td>\n",
       "      <td>221.936778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.971469</td>\n",
       "      <td>3.252022</td>\n",
       "      <td>4.438736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.879429</td>\n",
       "      <td>5800.0</td>\n",
       "      <td>353.752494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24071512_AD-18.0</th>\n",
       "      <td>178.374241</td>\n",
       "      <td>526.025556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>208.771884</td>\n",
       "      <td>3.567485</td>\n",
       "      <td>10.520511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.175438</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>252.465585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24071512_AD-21.0</th>\n",
       "      <td>198.640895</td>\n",
       "      <td>385.736076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.337505</td>\n",
       "      <td>3.972818</td>\n",
       "      <td>7.714722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.246750</td>\n",
       "      <td>13100.0</td>\n",
       "      <td>197.764201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  SaccadeSpeed_Mean  SaccadeSpeed_Max  SaccadeSpeed_Min  \\\n",
       "24071512_AD-3.0           82.640553        413.202767               0.0   \n",
       "24071512_AD-8.0          304.883800        654.553153               0.0   \n",
       "24071512_AD-10.0         162.601117        221.936778               0.0   \n",
       "24071512_AD-18.0         178.374241        526.025556               0.0   \n",
       "24071512_AD-21.0         198.640895        385.736076               0.0   \n",
       "\n",
       "                  SaccadeSpeed_Std  SaccadeAngel_Mean  SaccadeAngel_Max  \\\n",
       "24071512_AD-3.0         165.281107           1.652811          8.264055   \n",
       "24071512_AD-8.0         269.090155           6.097676         13.091063   \n",
       "24071512_AD-10.0         93.971469           3.252022          4.438736   \n",
       "24071512_AD-18.0        208.771884           3.567485         10.520511   \n",
       "24071512_AD-21.0        162.337505           3.972818          7.714722   \n",
       "\n",
       "                  SaccadeAngel_Min  SaccadeAngel_Std  SaccadeDelay  \\\n",
       "24071512_AD-3.0                0.0          3.305622        1820.0   \n",
       "24071512_AD-8.0                0.0          5.381803        3620.0   \n",
       "24071512_AD-10.0               0.0          1.879429        5800.0   \n",
       "24071512_AD-18.0               0.0          4.175438       11000.0   \n",
       "24071512_AD-21.0               0.0          3.246750       13100.0   \n",
       "\n",
       "                  TrajectoryDTW  \n",
       "24071512_AD-3.0      300.162880  \n",
       "24071512_AD-8.0      268.727935  \n",
       "24071512_AD-10.0     353.752494  \n",
       "24071512_AD-18.0     252.465585  \n",
       "24071512_AD-21.0     197.764201  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_id = video_list[4]\n",
    "print(video_id)\n",
    "video_res = single_video_res(all_people_fea=all_people_fea, video_id=video_id)\n",
    "pd.DataFrame(video_res).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
